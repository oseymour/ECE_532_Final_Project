{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# vectorize all of the images\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "# convert to black/white\n",
    "x_train_int = np.array([np.round(image/256) for image in x_train])\n",
    "x_test_int = np.array([np.round(image/256) for image in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 10 subsets of a digit or not a digit labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_zeros = np.array([1 if y_train[i]==0 else -1 for i in range(len(y_train))]).reshape(-1,1)\n",
    "y_ones  = np.array([1 if y_train[i]==1 else -1 for i in range(len(y_train))]).reshape(-1,1)\n",
    "y_twos  = np.array([1 if y_train[i]==2 else -1 for i in range(len(y_train))]).reshape(-1,1)\n",
    "y_threes= np.array([1 if y_train[i]==3 else -1 for i in range(len(y_train))]).reshape(-1,1)\n",
    "y_fours = np.array([1 if y_train[i]==4 else -1 for i in range(len(y_train))]).reshape(-1,1)\n",
    "y_fives = np.array([1 if y_train[i]==5 else -1 for i in range(len(y_train))]).reshape(-1,1)\n",
    "y_sixes = np.array([1 if y_train[i]==6 else -1 for i in range(len(y_train))]).reshape(-1,1)\n",
    "y_sevens= np.array([1 if y_train[i]==7 else -1 for i in range(len(y_train))]).reshape(-1,1)\n",
    "y_eights= np.array([1 if y_train[i]==8 else -1 for i in range(len(y_train))]).reshape(-1,1)\n",
    "y_nines = np.array([1 if y_train[i]==9 else -1 for i in range(len(y_train))]).reshape(-1,1)\n",
    "\n",
    "# one big array\n",
    "y_nums = np.array([y_zeros, y_ones, y_twos, y_threes, y_fours, y_fives, y_sixes, y_sevens, y_eights, y_nines])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at SVD decomp and decide which dimensions to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, VT = np.linalg.svd(x_train, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.log(s))\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Log of Singular Value')\n",
    "plt.title('Log of Singular Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explained variance vs number of singular values included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_adj = s / np.sum(s)\n",
    "comps = range(0,s.shape[0])\n",
    "expl_var = []\n",
    "for comp in comps:\n",
    "    expl_var.append(np.sum(s_adj[:comp]))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(comps, expl_var)\n",
    "ax.plot([ax.get_xlim()[0], ax.get_xlim()[1]], [0.9,0.9])\n",
    "ax.plot([345,345], [ax.get_ylim()[0],0.9])\n",
    "plt.title('Explained Variance vs. number of singular values used')\n",
    "plt.xlabel('Number of singular values included')\n",
    "plt.ylabel('Variance explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct training data using the most significant singular values, and then only first 2 and 3 principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = 345\n",
    "U_red = U[:,:keep]\n",
    "s_red = s[:keep]\n",
    "VT_red = VT[:keep,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_red = U_red @ np.diag(s_red) @ VT_red\n",
    "x_train2d = x_train @ VT[:2,:].T\n",
    "x_train3d = x_train @ VT[:3,:].T\n",
    "x_test2d = x_test @ VT[:2,:].T\n",
    "x_test3d = x_test @ VT[:3,:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = x_train @ VT[:3,:].T\n",
    "# %matplotlib notebook\n",
    "# fig = plt.figure(figsize=[10,10])\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(test[:,0], test[:,1], test[:,2], c=y_nines, cmap='jet')\n",
    "# plt.show()\n",
    "\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=[10,10])\n",
    "for label in np.unique(y_train):\n",
    "    truth = (y_train==label).reshape(-1)\n",
    "    ax.scatter(x_train2d[truth,0], x_train2d[truth,1], alpha=0.1, label=label)\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "leg = plt.legend(title='Digit classes')\n",
    "for lh in leg.legendHandles: \n",
    "    lh.set_alpha(1)\n",
    "plt.show()\n",
    "fig.savefig('all_one_plot.png', dpi=400, format='png')\n",
    "\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(nrows=5, ncols=2, figsize=[17.5/2,17.5])\n",
    "plt.subplots_adjust(hspace=0.32)\n",
    "for label in np.unique(y_train):\n",
    "    truth = (y_train==label).reshape(-1)\n",
    "    axis = ax[int(np.floor(label/2)), label%2]\n",
    "    axis.scatter(x_train2d[truth,0], x_train2d[truth,1], alpha=0.1, label=label)\n",
    "    axis.set_title('Digit class: ' + str(label))\n",
    "    axis.set_xlabel('$x_1$')\n",
    "    axis.set_ylabel('$x_2$')\n",
    "    axis.set_xlim([100,4000])\n",
    "    axis.set_ylim([-1500,2200])\n",
    "plt.show()\n",
    "fig.savefig('separate_subplots.png', dpi=400, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.imshow(x_train[0].reshape(28,28))\n",
    "ax2.imshow(x_train_red[0].reshape(28,28))\n",
    "plt.show()\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.imshow(x_train[1].reshape(28,28))\n",
    "ax2.imshow(x_train_red[1].reshape(28,28))\n",
    "plt.show()\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.imshow(x_train[2].reshape(28,28))\n",
    "ax2.imshow(x_train_red[2].reshape(28,28))\n",
    "plt.show()\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.imshow(x_train[3].reshape(28,28))\n",
    "ax2.imshow(x_train_red[3].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification for unreduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate weights for each linear classifier\n",
    "lamb = 0.01\n",
    "x = x_train\n",
    "inv = np.linalg.inv(x.T @ x + lamb*np.identity(x.shape[1]))\n",
    "first = inv @ x.T\n",
    "ws = np.zeros([10, x.shape[1], 1])\n",
    "for index, y in enumerate(y_nums):\n",
    "    ws[index] = first @ y\n",
    "    \n",
    "    \n",
    "# predict labels for training data\n",
    "yhat = -1*np.zeros([x.shape[0], 1])\n",
    "y = y_train\n",
    "for i, image in enumerate(x):\n",
    "    # get pred for each class\n",
    "    pred = [image @ ws[y] for y in range(10)]\n",
    "    yhat[i] = np.argmax(pred)\n",
    "print(classification_report(y, yhat))\n",
    "\n",
    "\n",
    "# predict labels for test data\n",
    "yhat = -1*np.zeros([x_test.shape[0], 1])\n",
    "x = x_test\n",
    "y = y_test\n",
    "for i, image in enumerate():\n",
    "    # get pred for each class\n",
    "    pred = [image @ ws[y] for y in range(10)]\n",
    "    yhat[i] = np.argmax(pred)\n",
    "print(classification_report(y, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification for truncated SVD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate weights for each linear classifier\n",
    "lamb = 0.01\n",
    "inv = np.linalg.inv(np.diag(s[:keep])**2 + lamb*np.identity(keep))\n",
    "first = VT_red.T @ inv @ np.diag(s[:keep]) @ U_red.T\n",
    "ws = np.zeros([10, 784, 1])\n",
    "for index, y in enumerate(y_nums):\n",
    "    ws[index] = first @ y\n",
    "    \n",
    "    \n",
    "# predict labels for training data\n",
    "yhat = -1*np.zeros([x.shape[0], 1])\n",
    "y = y_train\n",
    "for i, image in enumerate(x):\n",
    "    # get pred for each class\n",
    "    pred = [image @ ws[y] for y in range(10)]\n",
    "    yhat[i] = np.argmax(pred)\n",
    "print(classification_report(y, yhat))\n",
    "\n",
    "\n",
    "# predict labels for test data\n",
    "yhat = -1*np.zeros([x_test.shape[0], 1])\n",
    "x = x_test\n",
    "y = y_test\n",
    "for i, image in enumerate():\n",
    "    # get pred for each class\n",
    "    pred = [image @ ws[y] for y in range(10)]\n",
    "    yhat[i] = np.argmax(pred)\n",
    "print(classification_report(y, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification for 2D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate weights for each linear classifier\n",
    "lamb = 0.01\n",
    "x = x_train2d\n",
    "inv = np.linalg.inv(x.T @ x + lamb*np.identity(x.shape[1]))\n",
    "first = inv @ x.T\n",
    "ws = np.zeros([10, x.shape[1], 1])\n",
    "for index, y in enumerate(y_nums):\n",
    "    ws[index] = first @ y\n",
    "    \n",
    "    \n",
    "# predict labels for training data\n",
    "yhat = -1*np.zeros([x.shape[0], 1])\n",
    "y = y_train\n",
    "for i, image in enumerate(x):\n",
    "    # get pred for each class\n",
    "    pred = [image @ ws[y] for y in range(10)]\n",
    "    yhat[i] = np.argmax(pred)\n",
    "print(classification_report(y, yhat))\n",
    "\n",
    "\n",
    "# predict labels for test data\n",
    "yhat = -1*np.zeros([x_test.shape[0], 1])\n",
    "x = x_test2d\n",
    "y = y_test\n",
    "for i, image in enumerate():\n",
    "    # get pred for each class\n",
    "    pred = [image @ ws[y] for y in range(10)]\n",
    "    yhat[i] = np.argmax(pred)\n",
    "print(classification_report(y, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification for 3D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate weights for each linear classifier\n",
    "lamb = 0.01\n",
    "x = x_train3d\n",
    "inv = np.linalg.inv(x.T @ x + lamb*np.identity(x.shape[1]))\n",
    "first = inv @ x.T\n",
    "ws = np.zeros([10, x.shape[1], 1])\n",
    "for index, y in enumerate(y_nums):\n",
    "    ws[index] = first @ y\n",
    "    \n",
    "    \n",
    "# predict labels for training data\n",
    "yhat = -1*np.zeros([x.shape[0], 1])\n",
    "y = y_train\n",
    "for i, image in enumerate(x):\n",
    "    # get pred for each class\n",
    "    pred = [image @ ws[y] for y in range(10)]\n",
    "    yhat[i] = np.argmax(pred)\n",
    "print(classification_report(y, yhat))\n",
    "\n",
    "\n",
    "# predict labels for test data\n",
    "yhat = -1*np.zeros([x_test.shape[0], 1])\n",
    "x = x_test3d\n",
    "y = y_test\n",
    "for i, image in enumerate():\n",
    "    # get pred for each class\n",
    "    pred = [image @ ws[y] for y in range(10)]\n",
    "    yhat[i] = np.argmax(pred)\n",
    "print(classification_report(y, yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
